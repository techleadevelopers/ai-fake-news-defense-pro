# Risk Guardian Platform

Uma plataforma empresarial de defesa cognitiva e detecÃ§Ã£o de desinformaÃ§Ã£o em tempo real, projetada para identificar, analisar e mitigar campanhas de desinformaÃ§Ã£o coordenadas (CIB) e conteÃºdo gerado por IA (Deepfakes).

Este projeto utiliza uma arquitetura de microsserviÃ§os moderna, separando o frontend (React), o backend de orquestraÃ§Ã£o (NestJS) e o motor de inteligÃªncia artificial (Python/FastAPI).

---

## ðŸ—ï¸ Arquitetura do Sistema

A soluÃ§Ã£o Ã© composta por trÃªs componentes principais que devem ser executados em contÃªineres ou serviÃ§os separados:

1.  **Frontend (Client)**: Interface do usuÃ¡rio em React/Vite.
2.  **Backend (API Gateway & Orquestrador)**: NestJS com Prisma ORM.
3.  **AI Engine (Motor de InferÃªncia)**: Python com FastAPI/PyTorch.

### Fluxo de Dados

1.  O usuÃ¡rio envia uma URL ou Texto via Frontend.
2.  O Frontend chama a API do NestJS (`POST /api/scan`).
3.  O NestJS salva a requisiÃ§Ã£o no PostgreSQL (status: `PENDING`) e envia para a fila de processamento (RabbitMQ/Redis) ou chama o serviÃ§o Python diretamente.
4.  O Motor de IA (Python) processa o conteÃºdo (detecta fake news, deepfakes, sentimento).
5.  O Motor de IA devolve o resultado para o NestJS.
6.  O NestJS atualiza o banco de dados e notifica o frontend (via WebSocket ou Polling).

---

## ðŸš€ 1. Frontend (React + Vite)

Este repositÃ³rio contÃ©m o cÃ³digo fonte do frontend atual.

### PrÃ©-requisitos
*   Node.js 20+
*   npm ou yarn

### InstalaÃ§Ã£o e ExecuÃ§Ã£o
```bash
# Instalar dependÃªncias
npm install

# Rodar em modo de desenvolvimento
npm run dev:client
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em `http://localhost:5000`.

### Principais Bibliotecas
*   **UI**: TailwindCSS, Radix UI, Lucide Icons.
*   **Estado**: React Query (TanStack Query).
*   **GrÃ¡ficos**: Recharts.
*   **Mapas**: SVG Interativo Customizado.

---

## ðŸ› ï¸ 2. Backend (NestJS + Prisma)

> **Nota**: O cÃ³digo abaixo Ã© um guia de implementaÃ§Ã£o para ser criado em um repositÃ³rio separado ou na pasta `server/` se migrado para full-stack.

### Estrutura Recomendada
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth/           # AutenticaÃ§Ã£o (JWT, Passport)
â”‚   â”œâ”€â”€ scans/          # Gerenciamento de Scans
â”‚   â”œâ”€â”€ reports/        # GeraÃ§Ã£o de RelatÃ³rios
â”‚   â”œâ”€â”€ webhooks/       # IntegraÃ§Ãµes Externas
â”‚   â”œâ”€â”€ prisma/         # ServiÃ§o do Prisma
â”‚   â””â”€â”€ app.module.ts
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma   # DefiniÃ§Ã£o do Banco de Dados
â””â”€â”€ docker-compose.yml
```

### ConfiguraÃ§Ã£o Inicial

1.  **Criar projeto NestJS**:
    ```bash
    npm i -g @nestjs/cli
    nest new risk-guardian-backend
    cd risk-guardian-backend
    ```

2.  **Instalar Prisma e PostgreSQL**:
    ```bash
    npm install prisma --save-dev
    npm install @prisma/client
    npx prisma init
    ```

3.  **Definir Schema (`prisma/schema.prisma`)**:

    ```prisma
    generator client {
      provider = "prisma-client-js"
    }

    datasource db {
      provider = "postgresql"
      url      = env("DATABASE_URL")
    }

    model User {
      id        String   @id @default(uuid())
      email     String   @unique
      password  String
      role      Role     @default(ANALYST)
      scans     Scan[]
      createdAt DateTime @default(now())
    }

    model Scan {
      id            String      @id @default(uuid())
      content       String      @db.Text
      sourceUrl     String?
      status        ScanStatus  @default(PENDING)
      riskScore     Float?      // 0-100
      aiProbability Float?      // 0-100
      verdict       Verdict?
      metadata      Json?
      userId        String
      user          User        @relation(fields: [userId], references: [id])
      createdAt     DateTime    @default(now())
    }

    enum Role {
      ADMIN
      ANALYST
      VIEWER
    }

    enum ScanStatus {
      PENDING
      PROCESSING
      COMPLETED
      FAILED
    }

    enum Verdict {
      REAL
      FAKE
      SATIRE
      UNVERIFIED
    }
    ```

4.  **Rotas Consolidadas (Controllers)**:

    **Auth Controller (`auth.controller.ts`)**
    *   `POST /auth/login`: Retorna JWT.
    *   `POST /auth/register`: Cria novo usuÃ¡rio.

    **Scan Controller (`scans.controller.ts`)**
    *   `POST /scans`: Inicia uma nova anÃ¡lise.
        *   Body: `{ content: string, url?: string }`
    *   `GET /scans`: Lista histÃ³rico com paginaÃ§Ã£o.
    *   `GET /scans/:id`: Detalhes de uma anÃ¡lise.
    *   `POST /scans/:id/takedown`: Aciona webhook de remoÃ§Ã£o.

    **Dashboard Controller (`dashboard.controller.ts`)**
    *   `GET /dashboard/stats`: Retorna contadores (Total Scans, AmeaÃ§as Ativas).
    *   `GET /dashboard/virality`: Dados para o mapa de viralidade.

---

## ðŸ§  3. AI Engine (Python)

Este serviÃ§o deve expor uma API REST (FastAPI) ou consumir de uma fila para realizar a inferÃªncia pesada.

### Estrutura Recomendada
```
ai-engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # Entrypoint FastAPI
â”‚   â”œâ”€â”€ models/            # Modelos carregados (Torch/Pickle)
â”‚   â”œâ”€â”€ processors/        # LÃ³gica de limpeza de texto/imagem
â”‚   â””â”€â”€ routers/           # Rotas da API
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

### ImplementaÃ§Ã£o BÃ¡sica (`main.py`)

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import random # Substituir por inferÃªncia real

app = FastAPI(title="Risk Guardian AI Engine")

class ScanRequest(BaseModel):
    text: str
    url: str | None = None

class ScanResult(BaseModel):
    risk_score: float
    ai_probability: float
    verdict: str
    entities: list[str]

@app.post("/predict", response_model=ScanResult)
async def predict_risk(request: ScanRequest):
    # 1. Carregar modelo (ex: BERT fine-tuned)
    # 2. PrÃ©-processar texto
    # 3. InferÃªncia
    
    # SimulaÃ§Ã£o:
    risk_score = random.uniform(0, 100)
    ai_prob = random.uniform(0, 100)
    
    verdict = "REAL"
    if risk_score > 75:
        verdict = "FAKE"
    elif risk_score > 50:
        verdict = "UNVERIFIED"
        
    return {
        "risk_score": risk_score,
        "ai_probability": ai_prob,
        "verdict": verdict,
        "entities": ["entity1", "entity2"]
    }

@app.get("/health")
def health_check():
    return {"status": "online", "gpu_available": False}
```

### IntegraÃ§Ã£o NestJS -> Python

No serviÃ§o `ScanService` do NestJS, utilize o `HttpModule` para chamar o serviÃ§o Python:

```typescript
// scans.service.ts (Exemplo Conceitual)
async analyzeContent(text: string) {
  const aiResponse = await this.httpService.axiosRef.post('http://ai-engine:8000/predict', {
    text: text
  });
  
  return {
    riskScore: aiResponse.data.risk_score,
    verdict: aiResponse.data.verdict
    // ... mapear outros campos
  };
}
```

---

## ðŸ”„ Fluxo de Desenvolvimento Local (Full-Stack)

Para rodar todo o ecossistema localmente, recomenda-se o uso do Docker Compose.

**`docker-compose.yml` (Exemplo)**:

```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: riskguardian
    ports:
      - "5432:5432"

  backend:
    build: ./backend
    ports:
      - "3000:3000"
    environment:
      DATABASE_URL: postgres://user:password@postgres:5432/riskguardian
      AI_SERVICE_URL: http://ai-engine:8000
    depends_on:
      - postgres
      - ai-engine

  ai-engine:
    build: ./ai-engine
    ports:
      - "8000:8000"

  frontend:
    build: ./frontend
    ports:
      - "5000:5000"
```

## ðŸ“š DocumentaÃ§Ã£o Adicional

*   **API Specs**: A especificaÃ§Ã£o OpenAPI (Swagger) serÃ¡ gerada automaticamente pelo NestJS em `/api/docs`.
*   **Modelos de IA**: A documentaÃ§Ã£o dos modelos (acurÃ¡cia, datasets de treino) deve ser mantida na pasta `ai-engine/docs`.


# Risk Guardian Backend

Enterprise-grade backend platform for cognitive defense, real-time disinformation detection, and regulated AI orchestration.

Built with **NestJS**, this service acts as the **control plane** for AI-powered risk evaluation, governance, auditability, and real-time threat monitoring.

> âš ï¸ **AI DOES NOT DECIDE.**  
> This system evaluates, explains, and documents AI signals.  
> Final decisions are always human or policy-driven.

---

## ðŸŽ¯ Purpose

Risk Guardian Backend is designed to support **government, RegTech, and enterprise environments** that require:

- Explainable AI
- Uncertainty-aware predictions
- Full auditability
- Governance & compliance
- Secure orchestration of ML inference

---

## ðŸ—ï¸ High-Level Architecture

Frontend (React)
â†“
NestJS Backend (This Repo)
â†“
AI / ML Evaluation Services (FastAPI)

yaml
Copiar cÃ³digo

### Backend Responsibilities
- API Gateway & orchestration
- Authentication & RBAC
- Scan lifecycle management
- AI/ML inference coordination
- Governance & thresholds
- Audit trail (append-only)
- Alerts & takedown actions
- Real-time notifications

---

## ðŸ§± Tech Stack

- **Framework**: NestJS
- **Language**: TypeScript
- **Database**: PostgreSQL
- **ORM**: Prisma
- **Auth**: JWT + RBAC
- **Realtime**: WebSocket
- **Docs**: Swagger (OpenAPI)
- **Deployment**: Docker / Cloud-ready

---

## ðŸ“ Project Structure

src/
â”œâ”€â”€ auth/ # JWT authentication & RBAC
â”œâ”€â”€ users/ # User management
â”œâ”€â”€ scans/ # Core scan orchestration
â”œâ”€â”€ ml/ # AI & RegTech ML integration
â”œâ”€â”€ governance/ # Thresholds, policies, model cards
â”œâ”€â”€ dashboard/ # KPIs & analytics
â”œâ”€â”€ alerts/ # Alerts & takedown actions
â”œâ”€â”€ audit/ # Regulatory audit trail
â”œâ”€â”€ reports/ # Reports & exports
â”œâ”€â”€ webhooks/ # External integrations
â”œâ”€â”€ realtime/ # WebSocket events
â”œâ”€â”€ health/ # Health checks
â”œâ”€â”€ prisma/ # Prisma service
â”œâ”€â”€ common/ # Guards, DTOs, interceptors
â””â”€â”€ app.module.ts

yaml
Copiar cÃ³digo

---

## ðŸ” Security Model

- JWT-based authentication
- Role-Based Access Control (RBAC)
  - `ADMIN`
  - `ANALYST`
  - `VIEWER`
- Stateless services
- Input validation & guards
- Audit logs for every inference

---

## ðŸ§  Scan Lifecycle

PENDING â†’ PROCESSING â†’ COMPLETED | FAILED

yaml
Copiar cÃ³digo

Each scan includes:
- Raw input (text / URL)
- ML evaluation results
- Calibration & uncertainty
- Governance thresholds
- Full audit record

---

## ðŸ›ï¸ AI Governance Principles

âœ” Ensemble-based evaluation  
âœ” Score calibration (Platt / Isotonic)  
âœ” Uncertainty quantification  
âœ” Abstention for high uncertainty  
âœ” Threshold-based risk signaling  
âœ” Full explainability  
âœ” Model versioning  

---

## ðŸ“¡ API Endpoints

### ðŸ” Authentication
POST /auth/login
POST /auth/register
GET /auth/me

shell
Copiar cÃ³digo

### ðŸ‘¤ Users
GET /users
GET /users/:id
PATCH /users/:id/role

shell
Copiar cÃ³digo

### ðŸ§  Scans (Core)
POST /scans
GET /scans
GET /scans/:id
POST /scans/:id/retry
POST /scans/:id/cancel

shell
Copiar cÃ³digo

### ðŸ§ª ML / AI Integration
POST /ml/evaluate/full
POST /ml/evaluate/misinformation
POST /ml/evaluate/political
POST /ml/evaluate/impersonation
POST /ml/explain
GET /ml/health

shell
Copiar cÃ³digo

### ðŸ›ï¸ Governance
GET /governance/model-cards
GET /governance/release-policy
GET /governance/thresholds
GET /governance/bias-report/:scanId

shell
Copiar cÃ³digo

### ðŸ“Š Dashboard
GET /dashboard/stats
GET /dashboard/virality
GET /dashboard/timeline
GET /dashboard/risk-distribution

shell
Copiar cÃ³digo

### ðŸš¨ Alerts
POST /alerts
GET /alerts
POST /alerts/:id/ack
POST /alerts/:id/takedown

shell
Copiar cÃ³digo

### ðŸ§¾ Audit
GET /audit/logs
GET /audit/scans/:id
GET /audit/ml/:scanId

shell
Copiar cÃ³digo

### ðŸ“„ Reports
POST /reports
GET /reports
GET /reports/:id/download

shell
Copiar cÃ³digo

### ðŸ”Œ Webhooks
POST /webhooks/register
POST /webhooks/test
POST /webhooks/dispatch

shell
Copiar cÃ³digo

### âš¡ Realtime
WebSocket Events:

scan.created

scan.processing

scan.completed

scan.failed

alert.created

shell
Copiar cÃ³digo

### ðŸ©º Health
GET /health
GET /health/db
GET /health/ml

markdown
Copiar cÃ³digo

---

## ðŸ—„ï¸ Database Models

Core tables:
- `User`
- `Scan`
- `Alert`
- `AuditLog`
- `Report`
- `Webhook`
- `ModelCard`
- `ReleasePolicy`
- `BiasReport`
- `GovernanceThreshold`

All inference-related data is **append-only** for compliance.

---

## ðŸš€ Running Locally

### Requirements
- Node.js 20+
- PostgreSQL
- Docker (optional)

### Setup
```bash
npm install
cp .env.example .env
npx prisma generate
npx prisma db push
npm run start:dev
Access
API: http://localhost:5000

Swagger: http://localhost:5000/api/docs

â˜ï¸ Deployment
This backend is:

Cloud-native

Stateless

Horizontal-scalable

Ready for AWS / GCP / Azure

Compatible with Kubernetes

âš–ï¸ Legal & Compliance Notice
This system:

Does not make autonomous decisions

Provides risk evaluations only

Requires human or policy-based action

Is designed for regulated environments

ðŸ“Œ Status
âœ” Backend complete
âœ” Production-ready architecture
âœ” Frontend & ML integration ready

# ML Evaluation Service - Government/RegTech Level

## Overview
Explainable AI service for text analysis built with FastAPI.
**AI DOES NOT DECIDE - ONLY EVALUATES.**

All predictions are:
- Calibrated (Platt Scaling / Isotonic)
- Uncertainty-quantified
- Ensemble-validated (multiple models must agree)
- Auditable with full version control

## Architecture (Government Level)

```
ml/
â”œâ”€â”€ core/                    # Core ML infrastructure
â”‚   â”œâ”€â”€ inference/           # Ensemble inference (transformer, linear, rules)
â”‚   â”œâ”€â”€ calibration/         # Score calibration (Platt, Isotonic, Temperature)
â”‚   â”œâ”€â”€ uncertainty/         # Uncertainty quantification (MC Dropout, Conformal)
â”‚   â””â”€â”€ validation/          # Data quality gates (pre-inference)
â”œâ”€â”€ domains/                 # Domain-specific classifiers
â”‚   â”œâ”€â”€ defamation/          # Defamation detection
â”‚   â”œâ”€â”€ political/           # Political risk (extra FP caution)
â”‚   â”œâ”€â”€ misinformation/      # Fake news detection
â”‚   â””â”€â”€ impersonation/       # Identity fraud
â”œâ”€â”€ governance/              # Model governance
â”‚   â”œâ”€â”€ model_cards/         # Formal model documentation
â”‚   â”œâ”€â”€ release_policy/      # Deployment gates
â”‚   â””â”€â”€ thresholds/          # Threshold management
â”œâ”€â”€ quality/                 # Quality assurance
â”‚   â”œâ”€â”€ data_checks/         # Input validation
â”‚   â”œâ”€â”€ drift/               # Drift detection
â”‚   â””â”€â”€ bias/                # Fairness analysis
â”œâ”€â”€ text/                    # NLP modules (PT-BR)
â”œâ”€â”€ explainability/          # Model interpretability
â”œâ”€â”€ drift/                   # Drift detection (PSI/KL)
â”œâ”€â”€ serving/                 # Service orchestration
â””â”€â”€ registry/                # Model versioning
```

## Endpoints

### Government Level (v2.0.0)
| Endpoint | Method | Description |
|----------|--------|-------------|
| `/ml/text/risk-evaluate` | POST | Full Government-level risk evaluation |
| `/ml/text/political` | POST | Political risk analysis |
| `/ml/text/misinformation` | POST | Misinformation detection |
| `/ml/text/impersonation` | POST | Impersonation/fraud detection |
| `/ml/governance/model-cards` | GET | Model documentation |
| `/ml/governance/release-policy` | GET | Deployment gates config |
| `/ml/governance/bias-report/{id}` | GET | Bias/fairness analysis |

### Standard Endpoints
| Endpoint | Method | Description |
|----------|--------|-------------|
| `/ml/text/ai-detection` | POST | Risk classification |
| `/ml/text/defamation` | POST | Defamation detection |
| `/ml/text/ner` | POST | Named Entity Recognition |
| `/ml/explain` | POST | Explainability |
| `/ml/drift/status` | GET | Drift detection |
| `/ml/registry/models` | GET | Registered models |
| `/ml/registry/audit` | GET | Audit trail |
| `/ml/health` | GET | Health check |
| `/ml/docs` | GET | Swagger UI |

## Government Output Format

```json
{
  "raw_score": 0.82,
  "calibrated_score": 0.74,
  "confidence": 0.91,
  "uncertainty": 0.08,
  "agreement": 0.87,
  "prediction": "HIGH_RISK",
  "abstain": false,
  "signals": {
    "transformer": 0.81,
    "linear": 0.77,
    "rules": 0.65
  },
  "data_quality": {
    "score": 0.92,
    "issues": [],
    "usable": true
  },
  "calibration": {
    "raw_score": 0.82,
    "calibrated_score": 0.74,
    "method": "platt",
    "ece": 0.02
  },
  "uncertainty_details": {
    "total": 0.08,
    "epistemic": 0.05,
    "aleatoric": 0.06,
    "abstain": false
  },
  "model_version": "1.0.0",
  "model_hash": "abc123def456",
  "inference_time": 12.5
}
```

## Security Features

- **Stateless**: No state stored between requests
- **Data Quality Gates**: Invalid data blocked before inference
- **Ensemble Voting**: No single model decides
- **Uncertainty Threshold**: High uncertainty â†’ HUMAN_REVIEW
- **Circuit Breaker**: Automatic failover
- **Timeout**: 5 second limit
- **Audit Trail**: Every inference logged

## Calibration

- **Platt Scaling**: Logistic regression on raw scores
- **Isotonic Regression**: Non-parametric calibration
- **Temperature Scaling**: For neural network outputs
- **Metrics**: ECE, Brier Score, Reliability Curve

## Uncertainty Quantification

- **Monte Carlo Dropout**: Epistemic uncertainty
- **Conformal Prediction**: Prediction intervals
- **Abstention**: If uncertainty > 0.25 â†’ HUMAN_REVIEW

## Governance

### Model Cards
Each model has formal documentation:
- Purpose, intended use, prohibited use
- Dataset info, metrics, limitations
- Approval status, ethical considerations

### Release Policy
Deployment gates:
- min_precision: 0.92
- max_fp_political: 0.03
- max_uncertainty: 0.15
- requires_signoff: true

### Bias Detection
- FPR/FNR by protected group
- Disparity metrics
- Compliance reports

## Running

```bash
python main.py
```

Server runs on `http://0.0.0.0:5000`

## Last Updated
December 14, 2025


ðŸ“„ License
Tech Leader & Product Engineer: techleadevelopers
